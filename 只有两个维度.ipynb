{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from core.data_processor import DataLoader\n",
    "from core.model import Model\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_to_checkpoint(realdata, datetime):\n",
    "    # 这是针对于有header的打他frame？是这样吗？需要验证\n",
    "    checkpoint = realdata.loc[realdata['Date'] == datetime].index[0]\n",
    "    return checkpoint \n",
    "\n",
    "def convert_checkpoint_to_datetime(realdata, checkpoint):\n",
    "    datetime = realdata.iloc[checkpoint]['Date']\n",
    "    return datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020-01-13 尝试进行对 x_test 进行改造，从而提高效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = \"000738\"\n",
    "column = \"High\"\n",
    "startDate = \"2019-09-10\"\n",
    "sequence_length = \"7\"\n",
    "\n",
    "configs = json.load(open('configs/config.json', 'r'))\n",
    "if column == \"Close\" :\n",
    "    configs['data']['columns'] = [\"Close\", \"Open\"]\n",
    "elif column == \"High\" :\n",
    "    configs['data']['columns'] = [\"High\",  \"Open\"]\n",
    "elif column == \"Low\" :\n",
    "    configs['data']['columns'] = [\"Low\", \"Open\"]\n",
    "\n",
    "configs['data']['filename'] = stock + \".csv\"\n",
    "configs['data']['sequence_length'] = int(sequence_length)\n",
    "configs['model']['layers'][0]['input_timesteps'] = int(sequence_length) - 1\n",
    "\n",
    "\n",
    "model_save_dir = \"bestmodels/\" + sequence_length + \"/\" + stock + \"-\" + column + \".h5\"\n",
    "model = Model()\n",
    "model.load_model(model_save_dir)\n",
    "\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "data_windows = realdata.get(configs['data']['columns']).values[startPoint-configs['data']['sequence_length']:startPoint]\n",
    "\n",
    "def normalise_windows(window_data, single_window=False):\n",
    "    '''Normalise window with a base value of zero'''\n",
    "    normalised_data = []\n",
    "    window_data = [window_data] if single_window else window_data\n",
    "    for window in window_data:\n",
    "        normalised_window = []\n",
    "        for col_i in range(window.shape[1]):\n",
    "            normalised_col = [((float(p) / float(window[0, col_i])) - 1) for p in window[:, col_i]]\n",
    "            normalised_window.append(normalised_col)\n",
    "        normalised_window = np.array(normalised_window).T # reshape and transpose array back into original multidimensional format\n",
    "        normalised_data.append(normalised_window)\n",
    "    return np.array(normalised_data)\n",
    "\n",
    "\n",
    "# print(data_windows)\n",
    "data_windows = np.array(data_windows).astype(float)\n",
    "data_windows = normalise_windows(data_windows, single_window=True)\n",
    "\n",
    "predictions = model.predict_sequence_3(data_windows, 7)\n",
    "\n",
    "price_list = []\n",
    "for i in predictions :\n",
    "    price_list.append(realdata.loc[startPoint-configs['data']['sequence_length'],column] * (1 + i))\n",
    "\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.044081304, -0.04142143, -0.036856025]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stock = \"000738\"\n",
    "column = \"High\"\n",
    "startDate = \"2019-05-07\"\n",
    "# endDate = \"2019-08-27\"\n",
    "\n",
    "def predict(startDate, stock, column, sequence_length ):\n",
    "    configs = json.load(open('configs/config.json', 'r'))\n",
    "    model_save_dir = \"bestmodels/\" + sequence_length + \"/\" + stock + \"-\" + column + \".h5\"\n",
    "    \n",
    "    if column == \"Close\" :\n",
    "        configs['data']['columns'] = [\"Close\", \"Open\"]\n",
    "    elif column == \"High\" :\n",
    "        configs['data']['columns'] = [\"High\",  \"Open\"]\n",
    "    elif column == \"Low\" :\n",
    "        configs['data']['columns'] = [\"Low\", \"Open\"]\n",
    "\n",
    "    configs['data']['filename'] = stock + \".csv\"\n",
    "    configs['data']['sequence_length'] = int(sequence_length)\n",
    "    configs['model']['layers'][0]['input_timesteps'] = int(sequence_length) - 1\n",
    "    \n",
    "\n",
    "    data = DataLoader(\n",
    "        os.path.join('data', stock + \".csv\"),\n",
    "        0,\n",
    "        configs['data']['columns']\n",
    "    )\n",
    "    \n",
    "    x_test, y_test = data.get_test_data(\n",
    "        configs['data']['sequence_length'], \n",
    "        normalise=configs['data']['normalise']\n",
    "    )\n",
    "    model = Model()\n",
    "    model.load_model(model_save_dir)\n",
    "    \n",
    "    realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "    startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "    \n",
    "    # 需要找到 i， 第 i 个需要预测的数据。\n",
    "    prediction = model.predict_sequence_full(x_test[startPoint], configs['data']['sequence_length'])\n",
    "    \n",
    "    price_list = []\n",
    "    for i in prediction :\n",
    "        price_list.append(realdata.loc[startPoint,column] * (1 + i))\n",
    "\n",
    "    return price_list[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_5_predictions(startDate, stock, column):\n",
    "    p1 = predict(startDate, stock, column, \"3\")\n",
    "    p2 = predict(startDate, stock, column, \"4\")\n",
    "    p3 = predict(startDate, stock, column, \"5\")\n",
    "    p4 = predict(startDate, stock, column, \"6\")\n",
    "    p5 = predict(startDate, stock, column, \"7\")\n",
    "    \n",
    "    five_predictions = [p1, p2, p3, p4,p5]\n",
    "    predictions_frame = pd.DataFrame(seven_predictions) \n",
    "    \n",
    "    realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "    startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "    \n",
    "#     print( realdata.loc[startPoint+1:startPoint+3, [\"Date\", column] ].values[:] )\n",
    "    days = realdata.loc[startPoint+1:startPoint+3, [\"Date\", column] ].values[:]\n",
    "    \n",
    "    predictions = {\n",
    "        \"column\":column,\n",
    "        startDate:\n",
    "        {\n",
    "            days[0][0]:{\"mean\":predictions_frame[0].mean(),\"mid\":predictions_frame[0].median()},\n",
    "            days[1][0]:{\"mean\":predictions_frame[1].mean(),\"mid\":predictions_frame[1].median()},\n",
    "            days[2][0]:{\"mean\":predictions_frame[2].mean(),\"mid\":predictions_frame[2].median()}\n",
    "        }\n",
    "    }\n",
    "    file_to_save = \"predictions_result/\" + stock + \"_\" + column + \"_\" + startDate + \".json\"\n",
    "    \n",
    "    with open(file_to_save, 'w') as f:\n",
    "        json.dump(predictions, f)\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-03  High finish\n",
      "2019-01-03  Low finish\n",
      "2019-01-03  CLose finish\n",
      "2019-01-04  High finish\n",
      "2019-01-04  Low finish\n",
      "2019-01-04  CLose finish\n",
      "2019-01-07  High finish\n",
      "2019-01-07  Low finish\n",
      "2019-01-07  CLose finish\n",
      "2019-01-08  High finish\n",
      "2019-01-08  Low finish\n",
      "2019-01-08  CLose finish\n",
      "2019-01-09  High finish\n",
      "2019-01-09  Low finish\n",
      "2019-01-09  CLose finish\n",
      "2019-01-10  High finish\n",
      "2019-01-10  Low finish\n",
      "2019-01-10  CLose finish\n",
      "2019-01-11  High finish\n",
      "2019-01-11  Low finish\n",
      "2019-01-11  CLose finish\n",
      "2019-01-14  High finish\n",
      "2019-01-14  Low finish\n",
      "2019-01-14  CLose finish\n",
      "2019-01-15  High finish\n",
      "2019-01-15  Low finish\n",
      "2019-01-15  CLose finish\n",
      "2019-01-16  High finish\n",
      "2019-01-16  Low finish\n",
      "2019-01-16  CLose finish\n",
      "2019-01-17  High finish\n",
      "2019-01-17  Low finish\n",
      "2019-01-17  CLose finish\n",
      "2019-01-18  High finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "startDate = \"2019-01-18\"\n",
    "endDate = \"2019-01-31\"\n",
    "\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "endPoint = convert_datetime_to_checkpoint(realdata, endDate)\n",
    "\n",
    "days = realdata.loc[startPoint:endPoint, [\"Date\"] ].values\n",
    "\n",
    "# print(days)\n",
    "for day in days :\n",
    "    \n",
    "    give_me_5_predictions(day[0], stock, \"High\")\n",
    "    print(day[0], \" High finish\")\n",
    "    \n",
    "    give_me_5_predictions(day[0], stock, \"Low\")\n",
    "    print(day[0], \" Low finish\")\n",
    "    \n",
    "#     give_me_5_predictions(day[0], stock, \"Close\")\n",
    "#     print(day[0], \" CLose finish\")\n",
    "    \n",
    "# column = \"Low\"\n",
    "# give_me_5_predictions(startDate, stock, column)\n",
    "# print(\"high\")\n",
    "# column = \"High\"\n",
    "# give_me_5_predictions(startDate, stock, column)\n",
    "# print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = \"2019-01-03\"\n",
    "endDate = \"2019-01-31\"\n",
    "\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "endPoint = convert_datetime_to_checkpoint(realdata, endDate)\n",
    "\n",
    "days = realdata.loc[startPoint:endPoint, [\"Date\"] ].values\n",
    "\n",
    "# print(days)\n",
    "for day in days :\n",
    "    \n",
    "    give_me_5_predictions(startDate, stock, \"High\")\n",
    "    print(day[0], \" High finish\")\n",
    "    \n",
    "    give_me_5_predictions(startDate, stock, \"Low\")\n",
    "    print(day[0], \" Low finish\")\n",
    "    \n",
    "    give_me_5_predictions(startDate, stock, \"Close\")\n",
    "    print(day[0], \" CLose finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-23\n",
      "2019-08-23\n"
     ]
    }
   ],
   "source": [
    "startdate = \"2019-08-23\"\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "checkpoint = convert_datetime_to_checkpoint(realdata, startdate)\n",
    "date = convert_checkpoint_to_datetime(realdata, checkpoint)\n",
    "print(startdate)\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real data\n",
      "[['2019-08-13' 13.63]\n",
      " ['2019-08-14' 13.66]\n",
      " ['2019-08-15' 13.59]]\n",
      "data frame\n",
      "           0          1          2\n",
      "0  13.452866  13.530969  13.642185\n",
      "1  13.643313  13.676730  13.660977\n",
      "2  13.666673  13.643024  13.586893\n",
      "3  13.648509  13.685497  13.701070\n",
      "4  13.740333  13.758827  13.752094\n",
      "mean and median\n",
      "13.630338668505662 13.648509107055142\n",
      "13.659009544333443 13.676730103944427\n",
      "13.66864367374149 13.66097725968808\n"
     ]
    }
   ],
   "source": [
    "startDate = \"2019-08-12\"\n",
    "column = \"High\"\n",
    "give_me_5_predictions(startDate, stock, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542\n",
      "realdata             Date   Open   High    Low  Close     Volume       Amount\n",
      "4542  2019-04-30  13.95  14.22  13.88  14.14  5529309.0   78191416.0\n",
      "4543  2019-05-06  13.93  13.93  13.10  13.26  9729321.0  132145440.0\n",
      "[[1.395000e+01 1.422000e+01 1.388000e+01 1.414000e+01 5.529309e+06]\n",
      " [1.393000e+01 1.393000e+01 1.310000e+01 1.326000e+01 9.729321e+06]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "column = \"High\"\n",
    "\n",
    "startDate = \"2019-05-06\"\n",
    "\n",
    "\n",
    "startPoint = convert_datetime_to_checkpoint(realdata, startDate)\n",
    "print(startPoint)\n",
    "print(\"realdata\",realdata.loc[startPoint:startPoint+1,:] )\n",
    "\n",
    "data = DataLoader(\n",
    "    os.path.join('data', stock + \".csv\"),\n",
    "    0,\n",
    "    [\"Open\", \"High\", \"Low\", \"Close\",  \"Volume\"]\n",
    ")\n",
    "x_test, y_test = data.get_test_data(\n",
    "    3,\n",
    "    False\n",
    ")   \n",
    "\n",
    "print(x_test[startPoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "002609捷顺科技\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 10.339327789896167, 'mid': 10.447180206179619}, 'day2': {'mean': 10.315070630023722, 'mid': 10.61759547472}, 'day3': {'mean': 10.123764358519576, 'mid': 10.526777431964874}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 9.5138747605182, 'mid': 9.630221907794475}, 'day2': {'mean': 9.448371759254485, 'mid': 9.460135766491293}, 'day3': {'mean': 9.267974237583113, 'mid': 9.363899476975202}}}\n",
    "\n",
    "\n",
    "600173卧龙地产\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 5.220620113519952, 'mid': 5.230991631690412}, 'day2': {'mean': 5.213520888456143, 'mid': 5.209407236874104}, 'day3': {'mean': 5.215852158868685, 'mid': 5.207160414522513}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 5.143039583921433, 'mid': 5.136800385918468}, 'day2': {'mean': 5.156178324496606, 'mid': 5.169089575327234}, 'day3': {'mean': 5.168744796165265, 'mid': 5.182775970473886}}}\n",
    "\n",
    "{'column': 'High', '2020-01-15': {'day1': {'mean': 5.165439975213259, 'mid': 5.168776109218598}, 'day2': {'mean': 5.163824574235827, 'mid': 5.167480159848928}, 'day3': {'mean': 5.175807277050801, 'mid': 5.203082672771997}}}\n",
    "{'column': 'Low', '2020-01-15': {'day1': {'mean': 5.06853737151809, 'mid': 5.069604581221938}, 'day2': {'mean': 5.085844461421482, 'mid': 5.0918985132128}, 'day3': {'mean': 5.117732808148489, 'mid': 5.110968190599232}}}\n",
    "\n",
    "{'column': 'High', '2020-01-16': {'day1': {'mean': 5.113705769196153, 'mid': 5.1180160179734235}, 'day2': {'mean': 5.1152046435773375, 'mid': 5.109967353343964}, 'day3': {'mean': 5.133438510045409, 'mid': 5.140734442658722}}}\n",
    "{'column': 'Low', '2020-01-16': {'day1': {'mean': 5.034414397708141, 'mid': 5.0299963299930095}, 'day2': {'mean': 5.037874845735728, 'mid': 5.0429838576167825}, 'day3': {'mean': 5.05571470523253, 'mid': 5.056901103928685}}}\n",
    "\n",
    "002330 得利斯\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 7.863455103036015, 'mid': 7.8481212691403925}, 'day2': {'mean': 7.881653447290882, 'mid': 7.878932193741202}, 'day3': {'mean': 7.926459606273099, 'mid': 7.9366519411280745}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 7.6948678264440975, 'mid': 7.686873586103321}, 'day2': {'mean': 7.688281802614219, 'mid': 7.718941535563208}, 'day3': {'mean': 7.702413439498282, 'mid': 7.738762202099896}}}\n",
    "\n",
    "{'column': 'High', '2020-01-14': {'day1': {'mean': 8.002767618219368, 'mid': 8.006779143121094}, 'day2': {'mean': 7.992868902859743, 'mid': 8.021936438977718}, 'day3': {'mean': 7.976877808128483, 'mid': 8.032098140451126}}}\n",
    "{'column': 'Low', '2020-01-14': {'day1': {'mean': 7.7552635683719995, 'mid': 7.7564952159672975}, 'day2': {'mean': 7.7536509129568, 'mid': 7.751454677805305}, 'day3': {'mean': 7.750234682170674, 'mid': 7.742528327181936}}}\n",
    "\n",
    "{'column': 'High', '2020-01-15': {'day1': {'mean': 7.9481674963897095, 'mid': 7.945938410460949}, 'day2': {'mean': 7.940989894334459, 'mid': 7.9476602229941635}, 'day3': {'mean': 7.936431785805617, 'mid': 7.96319680508226}}}\n",
    "{'column': 'Low', '2020-01-15': {'day1': {'mean': 7.732247904066928, 'mid': 7.731997170117684}, 'day2': {'mean': 7.730306100908666, 'mid': 7.721463676868006}, 'day3': {'mean': 7.724774693765679, 'mid': 7.7080927794426675}}}\n",
    "\n",
    "600075 新疆天业\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 5.750655466716736, 'mid': 5.73742640428245}, 'day2': {'mean': 5.689212887441739, 'mid': 5.743211092436686}, 'day3': {'mean': 5.603083374865354, 'mid': 5.648190019056201}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 5.496698200725019, 'mid': 5.488259122520685}, 'day2': {'mean': 5.456035109698772, 'mid': 5.451947842352093}, 'day3': {'mean': 5.364975584279746, 'mid': 5.4102749960497025}}}\n",
    "\n",
    "\n",
    "\n",
    "603998 方盛制药\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 8.354911968340515, 'mid': 8.355935185824636}, 'day2': {'mean': 8.33000896484044, 'mid': 8.355991509385058}, 'day3': {'mean': 8.304637733893586, 'mid': 8.348202506378295}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 8.163344105912373, 'mid': 8.178749185381458}, 'day2': {'mean': 8.148445506231859, 'mid': 8.147460515582935}, 'day3': {'mean': 8.118201903646812, 'mid': 8.087863340806216}}}\n",
    "\n",
    "{'column': 'High', '2020-01-14': {'day1': {'mean': 8.31664386253804, 'mid': 8.326321915015578}, 'day2': {'mean': 8.293840672680293, 'mid': 8.301692797858268}, 'day3': {'mean': 8.265024733203347, 'mid': 8.253786385897547}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 8.150449786975049, 'mid': 8.16657861485146}, 'day2': {'mean': 8.127718433339147, 'mid': 8.113465018896386}, 'day3': {'mean': 8.097815688374453, 'mid': 8.060325473695993}}}\n",
    "\n",
    "{'column': 'High', '2020-01-15': {'day1': {'mean': 8.279258302239235, 'mid': 8.27904162539635}, 'day2': {'mean': 8.277851701615843, 'mid': 8.284646284137853}, 'day3': {'mean': 8.28718136269669, 'mid': 8.278772598993966}}}\n",
    "{'column': 'Low', '2020-01-15': {'day1': {'mean': 8.044640782684088, 'mid': 8.056528375446797}, 'day2': {'mean': 8.044298792928458, 'mid': 7.996280844509602}, 'day3': {'mean': 8.052553527237848, 'mid': 7.98344330996275}}}\n",
    "\n",
    "{'column': 'High', '2020-01-16': {'day1': {'mean': 8.187469031440326, 'mid': 8.086880313530566}, 'day2': {'mean': 8.18383722827281, 'mid': 8.145583908054977}, 'day3': {'mean': 8.197571618085961, 'mid': 8.24936379108578}}}\n",
    "{'column': 'Low', '2020-01-16': {'day1': {'mean': 7.986585931456181, 'mid': 7.9761676579713825}, 'day2': {'mean': 7.987802391385659, 'mid': 7.978933017849922}, 'day3': {'mean': 7.9977486086301495, 'mid': 7.998892441242933}}}\n",
    "\n",
    "600273嘉化能源\n",
    "{'column': 'High', '2020-01-13': {'day1': {'mean': 10.910883505138104, 'mid': 10.874304213495925}, 'day2': {'mean': 10.994302617192268, 'mid': 10.990348282307385}, 'day3': {'mean': 11.084564258004072, 'mid': 11.189982165135442}}}\n",
    "{'column': 'Low', '2020-01-13': {'day1': {'mean': 10.691568356418982, 'mid': 10.676240629116073}, 'day2': {'mean': 10.710502696000038, 'mid': 10.70697052582167}, 'day3': {'mean': 10.731257395051419, 'mid': 10.696877505518495}}}\n",
    "\n",
    "{'column': 'High', '2020-01-14': {'day1': {'mean': 11.123907582253217, 'mid': 11.115788582079112}, 'day2': {'mean': 11.125136738164349, 'mid': 11.082420478127897}, 'day3': {'mean': 11.098364255795257, 'mid': 11.035132964216173}}}\n",
    "{'column': 'Low', '2020-01-14': {'day1': {'mean': 10.799784548070281, 'mid': 10.806725251078605}, 'day2': {'mean': 10.772639211494475, 'mid': 10.699564927741886}, 'day3': {'mean': 10.723452732635662, 'mid': 10.609809467494488}}}\n",
    "\n",
    "{'column': 'High', '2020-01-15': {'day1': {'mean': 11.01316824213043, 'mid': 11.007201918493957}, 'day2': {'mean': 11.015777126967908, 'mid': 11.052130470704286}, 'day3': {'mean': 11.016971572100186, 'mid': 11.046759607214481}}}\n",
    "{'column': 'Low', '2020-01-15': {'day1': {'mean': 10.745288274005055, 'mid': 10.746666668280959}, 'day2': {'mean': 10.730064005831256, 'mid': 10.719865852501243}, 'day3': {'mean': 10.706753166927491, 'mid': 10.685701204612851}}}\n",
    "\n",
    "{'column': 'High', '2020-01-16': {'day1': {'mean': 11.149213262699543, 'mid': 11.16120946487412}, 'day2': {'mean': 11.101850966997443, 'mid': 11.07339643491432}, 'day3': {'mean': 11.035834569152446, 'mid': 11.010115441270171}}}\n",
    "{'column': 'Low', '2020-01-16': {'day1': {'mean': 10.703354554256425, 'mid': 10.711885266043245}, 'day2': {'mean': 10.713373922341502, 'mid': 10.703751208875328}, 'day3': {'mean': 10.722371608876623, 'mid': 10.695965564539655}}}\n",
    "\n",
    "{'column': 'High', '2020-01-17': {'day1': {'mean': 11.092546024728566, 'mid': 11.098714287159964}, 'day2': {'mean': 11.067618610302917, 'mid': 11.037269784696399}, 'day3': {'mean': 11.04615998565778, 'mid': 10.997244196394458}}}\n",
    "{'column': 'Low', '2020-01-17': {'day1': {'mean': 10.784088783726096, 'mid': 10.780402389168739}, 'day2': {'mean': 10.776653205498121, 'mid': 10.750415137019008}, 'day3': {'mean': 10.764232676979153, 'mid': 10.70493250804022}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column': 'High', '2020-01-17': {'day1': {'mean': 8.118469166553464, 'mid': 8.042929823212326}, 'day2': {'mean': 8.113778415266657, 'mid': 8.068895693756641}, 'day3': {'mean': 8.124018171419273, 'mid': 8.119538252204658}}}\n",
      "{'column': 'Low', '2020-01-17': {'day1': {'mean': 7.905419918972998, 'mid': 7.9019722822308545}, 'day2': {'mean': 7.91406833243277, 'mid': 7.955619077384472}, 'day3': {'mean': 7.93427318829298, 'mid': 7.8974467083811755}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'column': 'Low',\n",
       " '2020-01-17': {'day1': {'mean': 7.905419918972998, 'mid': 7.9019722822308545},\n",
       "  'day2': {'mean': 7.91406833243277, 'mid': 7.955619077384472},\n",
       "  'day3': {'mean': 7.93427318829298, 'mid': 7.8974467083811755}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prediction.predicting as pred\n",
    "\n",
    "pred.give_me_5_predictions(\"2020-01-17\", '603998', \"High\")\n",
    "pred.give_me_5_predictions(\"2020-01-17\", '603998', \"Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e69f09040184eb5b3a091f1682acf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(cells=(Cell(column_end=0, column_start=0, row_end=0, row_start=0, type='text', value='Hello'), Cell(colu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stock = \"603998\"\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "\n",
    "startDate = \"2019-09-04\"\n",
    "endDate = \"2019-09-18\"\n",
    "\n",
    "selected = realdata.loc[(realdata['Date'] > startDate) & (realdata['Date'] < endDate)]\n",
    "# print(selected[[\"Date\",\"High\",\"Low\"]])\n",
    "\n",
    "\n",
    "import ipysheet\n",
    "sheet = ipysheet.sheet(rows=3, columns=4)\n",
    "cell1 = ipysheet.cell(0, 0, 'Hello')\n",
    "cell2 = ipysheet.cell(2, 0, 'World')\n",
    "cell_value = ipysheet.cell(2,2, 42.)\n",
    "sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ipysheet import from_dataframe, to_dataframe, column, calculation, cell\n",
    "import ipysheet\n",
    "\n",
    "from traitlets import link\n",
    "from ipywidgets import HBox\n",
    "\n",
    "\n",
    "\n",
    "stock = \"000738\"\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "\n",
    "startDate = \"2019-02-11\"\n",
    "endDate = \"2019-02-22\"\n",
    "\n",
    "\n",
    "selected_df = realdata.loc[(realdata['Date'] > startDate) & (realdata['Date'] < endDate)]\n",
    "\n",
    "# predict_files_to_load \n",
    "for index, row in selected_df.iterrows():\n",
    "#     file_name = 'predictions_result/' + stock + \"_\" + row['Date'] + \".json\"\n",
    "    file = Path('predictions_result/' + stock + \"_\" + row['Date'] + \".json\")\n",
    "    if file.is_file():\n",
    "        with open(file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            '''\n",
    "            {\n",
    "                \"code\":'000738',\n",
    "                'Date': '2019-02-20',\n",
    "                \"predict_date\":'2019-02-21',\n",
    "                \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "                \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "            }\n",
    "            '''\n",
    "#             operation result\n",
    "            \n",
    "            '''\n",
    "            {\n",
    "                'initial_cash':1000000\n",
    "                \"code\":'000738',\n",
    "                'operation_date': '2019-02-21',\n",
    "                'p_h':13.44409406979382,\n",
    "                'p_l':13.44409406979382,\n",
    "                'r_h':13.10,\n",
    "                'r_l':12.80,\n",
    "                'if_sell':false,\n",
    "                'if_buy':true,\n",
    "                'buy_amount':3,\n",
    "                'sell_amount':4,\n",
    "                'cash_in':0,\n",
    "                'cash_out':3*13.44,\n",
    "                'remain_stock':3,\n",
    "                'remain_cash':87666,\n",
    "                'total_value':98765\n",
    "            }\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        print(\"file not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-11',\n",
    "    \"predict_date\":'2019-02-12',\n",
    "    \"high\":[13.3528405388984822,13.352840538898482,13.352840538898482,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d1 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-12',\n",
    "    \"predict_date\":'2019-02-13',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d2 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-13',\n",
    "    \"predict_date\":'2019-02-14',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d3 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-14',\n",
    "    \"predict_date\":'2019-02-15',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d4 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-15',\n",
    "    \"predict_date\":'2019-02-18',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d5 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-18',\n",
    "    \"predict_date\":'2019-02-19',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d6 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-19',\n",
    "    \"predict_date\":'2019-02-20',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d7 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-20',\n",
    "    \"predict_date\":'2019-02-21',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d8 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-20',\n",
    "    \"predict_date\":'2019-02-21',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}\n",
    "d9 = {\n",
    "    \"code\":'000738',\n",
    "    'Date': '2019-02-20',\n",
    "    \"predict_date\":'2019-02-21',\n",
    "    \"high\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382],\n",
    "    \"low\":[13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382,13.44409406979382]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e24a4e0955d45b48c3ffb968a7eb072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(cells=(Cell(choice=[], column_end=0, column_start=0, numeric_format=None, row_end=7, row_start=0, squeez…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ipysheet import from_dataframe, to_dataframe, column, calculation, cell\n",
    "import ipysheet\n",
    "\n",
    "from traitlets import link\n",
    "from ipywidgets import HBox\n",
    "\n",
    "\n",
    "\n",
    "stock = \"000738\"\n",
    "realdata = pd.read_csv('data/' + stock + '.CSV')\n",
    "\n",
    "startDate = \"2019-02-11\"\n",
    "endDate = \"2019-02-22\"\n",
    "# realdata['Buy'] = 0\n",
    "# realdata['Sell'] = 0\n",
    "realdata['Buy'] = 0\n",
    "realdata['Sell'] = 0\n",
    "realdata['buy_price'] = 0\n",
    "realdata['sell_price'] = 0\n",
    "\n",
    "selected_df = realdata.loc[(realdata['Date'] > startDate) & (realdata['Date'] < endDate)]\n",
    "\n",
    "# print(days)\n",
    "\n",
    "days = [d0, d1, d2, d3, d4, d5, d6, d7, d8]\n",
    "for data in days:\n",
    "    selected_df.at[realdata['Date']==data['predict_date'], 'buy_price']=np.mean(data['low'])\n",
    "    selected_df.at[realdata['Date']==data['predict_date'], 'sell_price']=np.mean(data['high'])\n",
    "\n",
    "# print(selected_df)   \n",
    "    \n",
    "    \n",
    "    \n",
    "# shift_df = selected_df.shift(-1)\n",
    "\n",
    "# for index, row in selected_df.iterrows():\n",
    "#     file_name = 'predictions_result/' + stock + \"_\" + row['Date'] + \".json\"\n",
    "#     my_file = Path(file_name)\n",
    "#     if my_file.is_file(): \n",
    "#         with open(file_name) as json_file:\n",
    "#             data = json.load(json_file)\n",
    "#             print(data)\n",
    "#             print()\n",
    "# #             selected_df.iloc[selected_df['Date']==row['Date']]['next_high'] = data['High']['predictions']['d1']['mean']\n",
    "# #             selected_df.iloc[selected_df['Date']==row['Date']]['next_low'] = data['Low']['predictions']['d1']['mean']\n",
    "# #             print(data['Date'])\n",
    "# #             print(data['High']['predictions']['d1'])\n",
    "# #             print(data['Low']['predictions']['d1'])\n",
    "#     else:\n",
    "#         print(file_name, \"file not exist\")\n",
    "#         print()\n",
    "\n",
    "# selected_df.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "sheet1 = from_dataframe(selected_df[[\"Date\", \"High\", \"Low\", \"buy_price\", 'sell_price', ]])\n",
    "\n",
    "# sheet = ipysheet.sheet()\n",
    "\n",
    "\n",
    "# # column2 = ipysheet.column(1, [1.] * 5)\n",
    "\n",
    "# # sheet\n",
    "# df2 = pd.DataFrame({'A': 1.,\n",
    "#                     'B': pd.Timestamp('20130102'),\n",
    "#                     'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "#                     'D': np.array([False, True, False, False], dtype='bool'),\n",
    "#                     'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "#                     'F': 'foo'})\n",
    "\n",
    "# df2.loc[[0, 2], ['B']] = np.nan\n",
    "\n",
    "# sheet2 = from_dataframe(df2)\n",
    "# # sheet2\n",
    "\n",
    "# sheet = ipysheet.sheet()\n",
    "\n",
    "# cell1 = ipysheet.cell(0, 0, slider, style={'min-width': '150px'})\n",
    "# cell3 = ipysheet.cell(2, 2, 42.)\n",
    "# cell_sum = ipysheet.cell(3, 2, 42.)\n",
    "\n",
    "# @calculation(inputs=[cell(row=1,column=1), cell(row=1,column=2)], output=cell(row=1,column=3))\n",
    "# def calculate(a, b):\n",
    "#     return a + b\n",
    "# print(cell(row=1,column=1))\n",
    "sheet1\n",
    "\n",
    "# HBox((sheet2, sheet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f955b6b29b474b69b58d272b804c652c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(cells=(Cell(choice=[], column_end=0, column_start=0, row_end=5, row_start=0, squeeze_row=False, type='nu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipysheet import from_dataframe, to_dataframe\n",
    "\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6, 26), index=dates, columns=list(chr(ord('A') + i) for i in range(26)))\n",
    "\n",
    "sheet = from_dataframe(df)\n",
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e463d123e284f26b129df94a7a71070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sheet(cells=(Cell(choice=[], column_end=0, column_start=0, row_start=0, squeeze_row=False, type='numeric', val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                    'B': pd.Timestamp('20130102'),\n",
    "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D': np.array([False, True, False, False], dtype='bool'),\n",
    "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    'F': 'foo'})\n",
    "\n",
    "df2.loc[[0, 2], ['B']] = np.nan\n",
    "\n",
    "sheet2 = from_dataframe(df2)\n",
    "sheet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A          B    C      D      E    F\n",
       "0  1.0        NaT  1.0  False   test  foo\n",
       "1  1.0 2013-01-02  1.0   True  train  foo\n",
       "2  1.0        NaT  1.0  False   test  foo\n",
       "3  1.0 2013-01-02  1.0  False  train  foo"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = to_dataframe(sheet2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f37589f7ea46f58cfa6c6c7fdb695a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Figure(axes=[Axis(scale=LinearScale()), Axis(orientation='vertical', scale=LinearScale())], fig…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from traitlets import link\n",
    "from ipywidgets import HBox\n",
    "import bqplot.pyplot as plt\n",
    "from ipysheet import sheet, cell, column\n",
    "\n",
    "size = 18\n",
    "scale = 100.\n",
    "np.random.seed(0)\n",
    "x_data = np.arange(size)\n",
    "y_data = np.cumsum(np.random.randn(size)  * scale)\n",
    "\n",
    "fig = plt.figure()\n",
    "axes_options = {'x': {'label': 'Date', 'tick_format': '%m/%d'},\n",
    "                'y': {'label': 'Price', 'tick_format': '0.0f'}}\n",
    "\n",
    "scatt = plt.scatter(x_data, y_data, colors=['red'], stroke='black')\n",
    "fig.layout.width = '70%'\n",
    "\n",
    "sheet1 = sheet(rows=size, columns=2)\n",
    "x_column = column(0, x_data)\n",
    "y_column = column(1, y_data)\n",
    "\n",
    "link((scatt, 'x'), (x_column, 'value'))\n",
    "link((scatt, 'y'), (y_column, 'value'))\n",
    "\n",
    "HBox((fig, sheet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920d3dfeac9d46ba9396a2ab4b7b8c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Search:'), Sheet(cells=(Cell(choice=[], column_end=0, column_start=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipysheet import from_dataframe\n",
    "from ipywidgets import Text, VBox, link\n",
    "\n",
    "df = pd.DataFrame({'A': 1.,\n",
    "                   'B': pd.Timestamp('20130102'),\n",
    "                   'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                   'D': np.array([False, True, False, False], dtype='bool'),\n",
    "                   'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                   'F': 'foo'})\n",
    "\n",
    "df.loc[[0, 2], ['B']] = np.nan\n",
    "\n",
    "\n",
    "s = from_dataframe(df)\n",
    "\n",
    "search_box = Text(description='Search:')\n",
    "link((search_box, 'value'), (s, 'search_token'))\n",
    "\n",
    "VBox((search_box, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_akshare_env",
   "language": "python",
   "name": "py3_akshare_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
